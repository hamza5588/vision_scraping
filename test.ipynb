{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader,CSVLoader\n",
    "\n",
    "loader = PyPDFLoader(r\"C:\\Users\\PMLS\\Desktop\\New folder (12)\\Modules6.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='1. Chat with PDF: This module integrates the functionality of chatting with the\\ncapability to handle PDF documents. Users can upload PDF files during their\\nconversation with the AI, enabling seamless communication while referring to\\nor discussing PDF content. This feature enhances user experience by providing a\\ncomprehensive platform for communication and document sharing. \\n2. PDF Summarizer with Selected Language: This module offers users the\\nability to summarize PDF documents using their preferred language. Users can\\nselect the language in which they want the summary generated, allowing for\\nbetter comprehension and accessibility. The AI extracts key information from\\nthe PDF and condenses it into a concise summary, making it easier for users to\\ngrasp the main points of the document efficiently. \\n3. Custom Image Creator: With the Custom Image Creator module, users can\\neffortlessly generate personalized images by providing prompts or descriptions.\\nUsers simply upload an image or describe their desired outcome, such as\\n\"looking like Batman,\" and the AI model generates an image based on the\\nprovided prompt. This intuitive interface allows users to unleash their creativity\\nwithout the need for advanced design skills. Whether it\\'s creating memes,\\ngenerating artwork, or visualizing concepts, the Custom Image Creator\\nempowers users to bring their ideas to life in a fun and engaging way. \\n4. Rewrite Content: This module enables users to effortlessly rewrite content\\nwhile maintaining its original meaning and context. Whether it\\'s for\\nparaphrasing articles, essays, or other textual content, the AI utilizes advanced\\nnatural language processing techniques to rewrite text effectively. Users can\\nimprove the readability, uniqueness, and coherence of their content, saving time\\nand effort in the process.\\n 5. Plagiarism Detection: This module checks the percentage of similarity\\nbetween AI-generated content and existing texts, helping users ensure the\\noriginality of their work and avoid unintentional duplicationNEW  MODULES', metadata={'source': 'C:\\\\Users\\\\PMLS\\\\Desktop\\\\New folder (12)\\\\Modules6.pdf', 'page': 0}),\n",
       " Document(page_content=\"Virtual try-on in the wild: Virtual try-on in the wild refers to using augmented\\nreality (AR) or virtual reality (VR) technology to allow users to try on clothing\\nvirtually in real-world settings. This can be done through smartphone apps or\\nspecialized devices like VR headsets. The technology uses computer-generated\\nimagery to overlay virtual clothing onto the user's live video feed or\\nenvironment, giving them a realistic preview of how the clothing would look on\\nthem before making a purchase. This immersive experience enhances online\\nshopping by providing a more interactive and personalized way for users to\\nexplore fashion options without physically trying on clothes.NEW  MODULES\", metadata={'source': 'C:\\\\Users\\\\PMLS\\\\Desktop\\\\New folder (12)\\\\Modules6.pdf', 'page': 1})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 5000 # For example, 1000 characters per chunk\n",
    "chunk_overlap = 500  # For example, 200 characters overlap between chunks\n",
    "\n",
    "# Initialize the RecursiveCharacterTextSplitter with specified chunk size and overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    ")\n",
    "documents = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey=\"sk-proj-WIqONjmhJjlNkeImihiWT3BlbkFJ0za2BbqjSwoZl6PyO7Bk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(openai_api_key=apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "llm = ChatGroq(\n",
    "temperature=0,\n",
    "model=\"llama3-70b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context do not involve a single word by your own same to same word should be output:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subheading in the new module is:\n",
      "\n",
      "\"Virtual try-on in the wild\"\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"what is the sub heading in new module\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
